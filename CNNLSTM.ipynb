{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AymxKi646Ja",
        "outputId": "a404f908-aa36-4c63-bd9c-08a9160f0efe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "4AymxKi646Ja"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdROLQeE5FQ2"
      },
      "outputs": [],
      "source": [
        "rootpath = '/content/drive/MyDrive/EEG Data/'"
      ],
      "id": "PdROLQeE5FQ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f872a942"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import butter, filtfilt\n",
        "from scipy.stats import zscore\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import torch.functional as F"
      ],
      "id": "f872a942"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93a07cc",
        "outputId": "d02c1104-f161-4379-9ec7-41f17757a514"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7eff1e984230>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "torch.manual_seed(0)"
      ],
      "id": "d93a07cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2998d90d"
      },
      "outputs": [],
      "source": [
        "class CNNLSTM(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    The codes implement the CNN model proposed in the paper \"Subject-Independent Drowsiness Recognition from Single-Channel EEG with an Interpretable CNN-LSTM model\".\n",
        "    The network is designed to classify 1D drowsy and alert EEG signals for the purposed of driver drowsiness recognition.\n",
        "      \n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(CNNLSTM, self).__init__()\n",
        "        self.feature=32\n",
        "        # self.padding= torch.nn.ReplicationPad2d((31,32,0,0))\n",
        "        self.conv = torch.nn.Conv2d(1,self.feature,(1,64))#,padding=(0,32),padding_mode='replicate')     \n",
        "        self.batch = Batchlayer(self.feature)          \n",
        "        self.avgpool = torch.nn.AvgPool2d((1,8))\n",
        "        self.fc = torch.nn.Linear(32, 2)        \n",
        "        self.softmax=torch.nn.LogSoftmax(dim=1)\n",
        "        self.softmax1=torch.nn.Softmax(dim=1)        \n",
        "        self.lstm=torch.nn.LSTM(32, 2)\n",
        "        # self.conv_new = torch.nn.Conv2d(30,1)\n",
        "        \n",
        "    def forward(self, source): \n",
        "        # source = self.padding(source)\n",
        "        # source = self.conv_new(source)\n",
        "        source = self.conv(source)\n",
        "        source = F.relu(source)\n",
        "        source = self.batch(source)\n",
        "        \n",
        "        source = torch.nn.ELU()(source) \n",
        "        source=self.avgpool(source)        \n",
        "        source =source.squeeze()\n",
        "        source=source.permute(2, 0, 1)\n",
        "        source = self.lstm(source)\n",
        "        source=source[1][0].squeeze()\n",
        "        source = self.softmax(source)   \n",
        "\n",
        "        return source \n",
        "\n",
        "\"\"\"\n",
        "We use the batch normalization layer implemented by ourselves for this model instead using the one provided by the Pytorch library.\n",
        "In this implementation, we do not use momentum and initialize the gamma and beta values in the range (-0.1,0.1). \n",
        "We have got slightly increased accuracy using our implementation of the batch normalization layer.\n",
        "\"\"\"\n",
        "def normalizelayer(data):\n",
        "    eps=1e-05\n",
        "    a_mean=data-torch.mean(data, [0,2,3],True).expand(int(data.size(0)), int(data.size(1)), int(data.size(2)),int(data.size(3)))\n",
        "    b=torch.div(a_mean,torch.sqrt(torch.mean((a_mean)**2, [0,2,3],True)+eps).expand(int(data.size(0)), int(data.size(1)), int(data.size(2)),int(data.size(3))))\n",
        "    \n",
        "    return b\n",
        "\n",
        "class Batchlayer(torch.nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super(Batchlayer, self).__init__()\n",
        "        self.gamma=torch.nn.Parameter(torch.Tensor(1,dim,1,1))\n",
        "        self.beta=torch.nn.Parameter(torch.Tensor(1,dim,1,1))\n",
        "        self.gamma.data.uniform_(-0.1, 0.1)\n",
        "        self.beta.data.uniform_(-0.1, 0.1)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        data=normalizelayer(input)\n",
        "        gammamatrix=self.gamma.expand(int(data.size(0)), int(data.size(1)), int(data.size(2)),int(data.size(3)))\n",
        "        betamatrix = self.beta.expand(int(data.size(0)), int(data.size(1)), int(data.size(2)),int(data.size(3)))\n",
        "        \n",
        "        return data*gammamatrix+betamatrix"
      ],
      "id": "2998d90d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv_tH6Kd5tu8"
      },
      "outputs": [],
      "source": [
        "def bp_filter(data, f_lo, f_hi, fs):\n",
        "    \"\"\" Digital band pass filter (6-th order Butterworth)\n",
        "    Args:\n",
        "        data: numpy.array, time along axis 0\n",
        "        (f_lo, f_hi): frequency band to extract [Hz]\n",
        "        fs: sampling frequency [Hz]\n",
        "    Returns:\n",
        "        data_filt: band-pass filtered data, same shape as data \"\"\"\n",
        "    data_filt = np.zeros_like(data)\n",
        "    f_ny = fs / 2.  # Nyquist frequency\n",
        "    b_lo = f_lo / f_ny  # normalized frequency [0..1]\n",
        "    b_hi = f_hi / f_ny  # normalized frequency [0..1]\n",
        "    # band-pass filter parameters\n",
        "    p_lp = {\"N\":6, \"Wn\":b_hi, \"btype\":\"lowpass\", \"analog\":False, \"output\":\"ba\"}\n",
        "    p_hp = {\"N\":6, \"Wn\":b_lo, \"btype\":\"highpass\", \"analog\":False, \"output\":\"ba\"}\n",
        "    bp_b1, bp_a1 = butter(**p_lp)\n",
        "    bp_b2, bp_a2 = butter(**p_hp)\n",
        "    data_filt = filtfilt(bp_b1, bp_a1, data, axis=0)\n",
        "    data_filt = filtfilt(bp_b2, bp_a2, data_filt, axis=0)\n",
        "    return data_filt\n",
        "\n",
        "def get_EEG_data(data_root, filename):\n",
        "    # Extract the data from one of these files.\n",
        "    hz = 128\n",
        "    #filename = 'eeg_record30.mat'\n",
        "    mat = sio.loadmat(data_root + filename)\n",
        "    data = pd.DataFrame.from_dict(mat[\"o\"][\"data\"][0,0])\n",
        "\n",
        "    # Limit the data to the 7 valid EEG leads.\n",
        "    dat = data.filter(list(range(3, 17)))\n",
        "    dat.columns = list(range(1, 15))\n",
        "    dat = dat.filter([2, 3, 6, 7, 8, 9, 14], axis=1)\n",
        "    labels = ['F7', 'F3', 'T5', 'O1', 'O2', 'T6', 'FP2']  # FP2 should really be AF4\n",
        "    dat.columns = labels\n",
        "\n",
        "    # Filter the data, high pass 2 Hz, low pass 40 Hz.\n",
        "    lo, hi = 0.5, 40\n",
        "    # Do the filtering.  get 0.5-40hz\n",
        "    datf = bp_filter(dat.to_numpy(), lo, hi, hz)\n",
        "\n",
        "    # Convert back to a dataframe.\n",
        "    dat = pd.DataFrame({c: datf[:, i] for i,c in enumerate(labels)})\n",
        "\n",
        "    # Z-transform each column\n",
        "    dat = dat.apply(zscore)\n",
        "    \n",
        "    return dat\n",
        "\n",
        "def plotAll(dat, leads, start, seconds, hz):\n",
        "    plt.figure(figsize=(30,10))\n",
        "    for i, lead in enumerate(leads):   \n",
        "        length = dat.loc[start: start + seconds * hz, lead].shape\n",
        "        print(length)\n",
        "        plt.plot(dat.loc[start: start + seconds * hz, lead],label=lead)   \n",
        "    plt.title('multi-channel EEG signal')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def saveAll(dat,leads, start, seconds, hz):\n",
        "    plt.figure(figsize=(30,10))\n",
        "    for i, lead in enumerate(leads):   \n",
        "        print(type(dat.loc[start: start + seconds * hz, lead]))\n",
        "        dat.loc[start: start + seconds * hz, lead]\n",
        "        \n",
        "        \n",
        "    # plt.title('multi-channel EEG signal')\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "\n",
        "def signal_append(data,front,behind):\n",
        "  # change data set shape to (length-2,front+dat.shape[1]+behind)\n",
        "  # dat = dataset\n",
        "  # front : the length of data append in the front of the data slice\n",
        "  # behind : the length of data append behind the data slice\n",
        "  # return dataset as numpy\n",
        "    o_shape = data.shape # original data set shape\n",
        "    n_shape = (data.shape[0]-2,front+data.shape[1]+behind)\n",
        "    data_set = np.zeros((n_shape[0],n_shape[1]))\n",
        "    # print(data_set.shape)\n",
        "    for i,item in enumerate(data):\n",
        "      if i == 0:\n",
        "        continue\n",
        "      if i == o_shape[0]-1:\n",
        "        break\n",
        "      data_pre = data[i-1]\n",
        "      data_now = data[i]\n",
        "      data_next = data[i+1]\n",
        "      # print(i)\n",
        "      data_set[i-1] = np.concatenate((data_pre[-1*front:],data_now,data_next[0:behind]),axis = 0)\n",
        "    return data_set\n",
        "\n",
        "def signal_slice(dat,channel, start, seconds, hz, time_len, front,behind):  \n",
        "  # time_len : data time after slice in seconds\n",
        "      data_shape = dat.shape\n",
        "      new_set = []\n",
        "      for i in range(start,start+time_len*hz,seconds*hz):\n",
        "          new_set.append(dat.loc[i: i + seconds * hz-1, channel])\n",
        "      new_set = np.array(new_set)\n",
        "      new_set = signal_append(new_set,front, behind)\n",
        "      return new_set\n",
        "\n",
        "# def create_label():\n"
      ],
      "id": "nv_tH6Kd5tu8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIag5DL9LvdC",
        "outputId": "89e48147-2a9d-409e-fadd-11a8648d4428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eeg_record1.mat', 'eeg_record10.mat', 'eeg_record12.mat', 'eeg_record11.mat', 'eeg_record13.mat', 'eeg_record14.mat', 'eeg_record16.mat', 'eeg_record15.mat', 'eeg_record18.mat', 'eeg_record17.mat', 'eeg_record2.mat', 'eeg_record19.mat', 'eeg_record20.mat', 'eeg_record21.mat', 'eeg_record22.mat', 'eeg_record23.mat', 'eeg_record25.mat', 'eeg_record24.mat', 'eeg_record27.mat', 'eeg_record26.mat', 'eeg_record29.mat', 'eeg_record28.mat', 'eeg_record30.mat', 'eeg_record3.mat', 'eeg_record31.mat', 'eeg_record33.mat', 'eeg_record32.mat', 'eeg_record34.mat', 'eeg_record5.mat', 'eeg_record4.mat', 'eeg_record7.mat', 'eeg_record6.mat', 'eeg_record8.mat', 'eeg_record9.mat']\n"
          ]
        }
      ],
      "source": [
        "filelist = os.listdir(rootpath)\n",
        "print(filelist[0:-1])"
      ],
      "id": "AIag5DL9LvdC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4Jnfs7n_X3r"
      },
      "outputs": [],
      "source": [
        "from logging import root\n",
        "channels = ['F7', 'F3', 'T5', 'O1', 'O2', 'T6', 'FP2']\n",
        "start = 0\n",
        "seconds = 3\n",
        "hz = 128\n",
        "\n",
        "\n",
        "# def gen_dataset(rootpath,channel):\n",
        "#   data = pd.DataFrame()\n",
        "#   label = pd.DataFrame()\n",
        "#   for i,f in enumerate(filelist[0:-1]):\n",
        "#     name = f[0:-4]\n",
        "#       # print(name)  \n",
        "#     dat = get_EEG_data(rootpath, f)\n",
        "#     label[str(i)] = np.concatenate((np.zeros(199),np.ones(199)),axis=0).tolist()   \n",
        "#     data[str(i)] = signal_slice(dat,channel,0,3,128,1200,31,32).tolist()\n",
        "#   return data,label\n",
        " \n",
        "\n",
        "def gen_dataset(rootpath,channel):\n",
        "  data = []\n",
        "  label = []\n",
        "  for i,f in enumerate(filelist[0:-1]):\n",
        "    name = f[0:-4]\n",
        "      # print(name)  \n",
        "    dat = get_EEG_data(rootpath, f)\n",
        "    label.append(np.concatenate((np.zeros(199),np.ones(199)),axis=0))\n",
        "    data.append(signal_slice(dat,channel,0,3,128,1200,31,32))\n",
        "  return np.array(data),np.array(label)\n",
        "\n",
        "\n",
        "# data.shape\n",
        "dataset, labelset = gen_dataset(rootpath,'O1')\n",
        "\n"
      ],
      "id": "C4Jnfs7n_X3r"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdMh0B53wP1p",
        "outputId": "0442ba43-2860-4cc4-8044-738cef17b5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34, 398)\n"
          ]
        }
      ],
      "source": [
        "print(labelset.shape)"
      ],
      "id": "pdMh0B53wP1p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arIH0M7hWMU7"
      },
      "outputs": [],
      "source": [
        "def channel_data_per_subject(dataset,labelset):\n",
        "  subject_data = pd.DataFrame()\n",
        "  subject_label = pd.DataFrame()\n",
        "  subject_num = 5\n",
        "  # namelist = [f[0:-4] for f in filelist]\n",
        "  # channels_t = ['O1','O2']\n",
        "  s = 1\n",
        "  data = []\n",
        "  label = []\n",
        "  for i in range(len(filelist)-1):\n",
        "    data = np.concatenate((data,dataset[str(i)]),axis=0)\n",
        "    label = np.concatenate((label,labelset[str(i)]),axis=0)\n",
        "    if i%7 == 6 or i == 33:\n",
        "      subject_data[str(s)] = pd.Series(data)\n",
        "      subject_label[str(s)] = pd.Series(label)\n",
        "      data = []\n",
        "      label = []\n",
        "      s = s + 1\n",
        "  return subject_data,subject_label\n",
        "\n",
        "def channel_data_per_subject(dataset,labelset):\n",
        "  subject_data = np.zeros(5)\n",
        "  subject_data[0]\n",
        "  return subject_data,subject_label"
      ],
      "id": "arIH0M7hWMU7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "cpVphekW18vY",
        "outputId": "dcee1efa-7757-4c60-e5bf-3eff018d9614"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ae029f38620d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubject_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubject_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ],
      "source": [
        "# subject_data = np.zeros(5)\n",
        "# subject_data[0] = np.concatenate((dataset[0],dataset[1],dataset[2],dataset[3],dataset[4],dataset[5],dataset[6]),axis=0)"
      ],
      "id": "cpVphekW18vY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EekgVu273RGM"
      },
      "outputs": [],
      "source": [
        "# xdata= dataset.reshape(dataset.shape[0]*dataset.shape[1],dataset.shape[2])\n",
        "# ydata = labelset.reshape(labelset.shape[0]*labelset.shape[1])\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# X_train,X_test,y_train,y_test = train_test_split(xdata,ydata,test_size=0.2, random_state=42)\n"
      ],
      "id": "EekgVu273RGM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "z3kdNaWJ4mcN",
        "outputId": "8e72d3d5-21f3-4b51-82e4-76d1aeea1371"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-181-12d6de9458e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mloss_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNLLLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-047e3621895f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'kernel_size'"
          ]
        }
      ],
      "source": [
        "# my_net = CNNLSTM().double().cuda()\n",
        "# optimizer = optim.Adam(my_net.parameters(), lr=lr)    \n",
        "# loss_class = torch.nn.NLLLoss().cuda()"
      ],
      "id": "z3kdNaWJ4mcN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "154d7a5e",
        "outputId": "e16fe2a6-cf15-4edf-aa07-b8354dea3484"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__() takes at least 4 arguments (3 given)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a2622fdc21d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-a2622fdc21d8>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#       load the CNN model to deal with 1D EEG signals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mmy_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-047e3621895f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes at least 4 arguments (3 given)"
          ]
        }
      ],
      "source": [
        "def run(data,label):\n",
        "\n",
        "#    load data from the file\n",
        "    # filename = r'dataset.mat' \n",
        "    \n",
        "    # tmp = sio.loadmat(filename)\n",
        "    # xdata=np.array(tmp['EEGsample'])\n",
        "    # label=np.array(tmp['substate'])\n",
        "    # subIdx=np.array(tmp['subindex'])\n",
        "\n",
        "    # label.astype(int)\n",
        "    # subIdx.astype(int)\n",
        "    \n",
        "    # samplenum=label.shape[0]\n",
        "    \n",
        "#   there are 11 subjects in the dataset. Each sample is 3-seconds data from 30 channels with sampling rate of 128Hz. \n",
        "    # channelnum=30\n",
        "    # subjnum=11\n",
        "    # samplelength=3\n",
        "    # sf=128\n",
        "    \n",
        "#   define the learning rate, batch size and epoches\n",
        "    # lr=1e-2 \n",
        "    # batch_size = 50\n",
        "    # n_epoch =15 \n",
        "    \n",
        "#   ydata contains the label of samples\n",
        "    # xdata =    \n",
        "    ydata=np.zeros(samplenum,dtype=np.longlong)\n",
        "    \n",
        "    for i in range(samplenum):\n",
        "        ydata[i]=label[i]\n",
        "\n",
        "#   only channel 28 is used, which corresponds to the Oz channel\n",
        "#     selectedchan=[28]\n",
        "#     selectedchen=[28]\n",
        "    \n",
        "#   update the xdata and channel number\n",
        "#     print(xdata)\n",
        "#     xdata=xdata[:,selectedchan,:]\n",
        "#     print(xdata.head)\n",
        "#     channelnum=len(selectedchan)\n",
        "    \n",
        "#   the result stores accuracies of every subject     \n",
        "    results=np.zeros(subjnum)\n",
        "  \n",
        "    \n",
        "#   it performs leave-one-subject-out training and classfication \n",
        "#   for each iteration, the subject i is the testing subject while all the other subjects are the training subjects.      \n",
        "    for i in range(1,subjnum+1):\n",
        "\n",
        "#       form the training data        \n",
        "        trainindx=np.where(subIdx != i)[0] \n",
        "        xtrain=xdata[trainindx]   \n",
        "        x_train = xtrain.reshape(xtrain.shape[0],1,channelnum, samplelength*sf)\n",
        "        y_train=ydata[trainindx]\n",
        "        \n",
        "#       form the testing data         \n",
        "        testindx=np.where(subIdx == i)[0]    \n",
        "        xtest=xdata[testindx]\n",
        "        x_test = xtest.reshape(xtest.shape[0], 1,channelnum, samplelength*sf)\n",
        "        y_test=ydata[testindx]\n",
        "    \n",
        "\n",
        "        train = torch.utils.data.TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
        "        train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    #       load the CNN model to deal with 1D EEG signals\n",
        "        my_net = CNNLSTM().double().cuda()\n",
        "\n",
        "   \n",
        "        optimizer = optim.Adam(my_net.parameters(), lr=lr)    \n",
        "        loss_class = torch.nn.NLLLoss().cuda()\n",
        "\n",
        "        for p in my_net.parameters():\n",
        "            p.requires_grad = True    \n",
        "  \n",
        "    #        train the classifier \n",
        "        for epoch in range(n_epoch):   \n",
        "            for j, data in enumerate(train_loader, 0):\n",
        "                inputs, labels = data                \n",
        "                \n",
        "                input_data = inputs.cuda()\n",
        "                class_label = labels.cuda()              \n",
        "\n",
        "                my_net.zero_grad()               \n",
        "                my_net.train()          \n",
        "   \n",
        "                class_output= my_net(input_data) \n",
        "                err_s_label = loss_class(class_output, class_label)\n",
        "                err = err_s_label \n",
        "             \n",
        "                err.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "    #       test the results\n",
        "        my_net.train(False)\n",
        "        with torch.no_grad():\n",
        "            x_test =  torch.DoubleTensor(x_test).cuda()\n",
        "            answer = my_net(x_test)\n",
        "            probs= answer.cpu().numpy()\n",
        "            preds = probs.argmax(axis = -1)  \n",
        "            acc=accuracy_score(y_test, preds)\n",
        "\n",
        "            print(acc)\n",
        "            results[i-1]=acc\n",
        "            \n",
        "            \n",
        "    print('mean accuracy:',np.mean(results))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()"
      ],
      "id": "154d7a5e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa442e1a",
        "outputId": "9c0409dd-76ec-446e-cf21-1f0f0e4fe279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(np.array(subject_data['1'][0])))"
      ],
      "id": "fa442e1a"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "conda_pytorch_p27",
      "language": "python",
      "name": "conda_pytorch_p27"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}